{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our basic libraries\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# data loading and transforming\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: you can try changing the batch_size to be larger or smaller\n",
    "## when you get to training your network, see how batch_size affects the loss\n",
    "batch_size=20\n",
    "\n",
    "# The output of torchvision datasets are PILImage images of range [0, 1]. \n",
    "# We transform them to Tensors for input into a CNN\n",
    "data_transform = transforms.ToTensor()\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = FashionMNIST('F_MNIST_data/', download=True, train=True, transform=data_transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = FashionMNIST('F_MNIST_data/', download=True, train=False, transform=data_transform)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data, number of images:  60000\n",
      "Test data, number of images:  10000\n"
     ]
    }
   ],
   "source": [
    "print('Train data, number of images: ', len(trainset))\n",
    "print('Test data, number of images: ', len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 28, 28])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f75e8438eb8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        # 1 input image channel (grayscale), 10 output channels/feature maps\n",
    "        # 3x3 square convolution kernel\n",
    "        # from (1, 28, 28) to (10, 26, 26)\n",
    "        self.conv1 = nn.Conv2d(1, 10, 3)\n",
    "        \n",
    "        ## TODO: Define the rest of the layers:\n",
    "        # include another conv layer, maxpooling layers, and linear layers\n",
    "        # also consider adding a dropout layer to avoid overfitting\n",
    "        # from (10, 26, 26) to (10, 13, 13)\n",
    "        # from (20, 11, 11) to (20, 5, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # from (10, 13, 13) to (20, 11, 11)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3)\n",
    "        \n",
    "        \n",
    "        # from (20, 5, 5) to (10)\n",
    "        self.fc1 = nn.Linear(20*5*5, 10)\n",
    "        \n",
    "\n",
    "    ## TODO: define the feedforward behavior\n",
    "    def forward(self, x):\n",
    "        # one activated conv layer\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        \n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        # one linear layer\n",
    "        x = F.relu(self.fc1(x))\n",
    "        # a softmax layer to convert the 10 outputs into a distribution of class scores\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        \n",
    "        # final output\n",
    "        return x\n",
    "\n",
    "\n",
    "# instantiate and print your Net\n",
    "model = Model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross entropy loss combines softmax and nn.NLLLoss() in one single class.\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# stochastic gradient descent with a small learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(n_epochs):\n",
    "    loss_over_time = []\n",
    "    \n",
    "    # move model to GPU\n",
    "    #model.to(\"cuda\")\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        batch_i = 0\n",
    "        for images, labels in iter(trainloader):\n",
    "            \n",
    "            # move images and label tensors to GPU\n",
    "            #images = images.to(\"cuda\")\n",
    "            #labels = labels.to(\"cuda\")\n",
    "            \n",
    "            \n",
    "            #zero the weight gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward pass to get outputs\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # backward pass to calculate the parameter gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # update the parameters\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print loss statistics\n",
    "            # to convert loss into a scalar and add it to running_loss, we use .item()\n",
    "            epoch_loss = loss.item()\n",
    "            batch_i+=batch_size\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if batch_i%20000 == 0:    # print every 1000 batches\n",
    "                avg_loss = running_loss/1000\n",
    "                # record and print the avg loss over the 1000 batches\n",
    "                loss_over_time.append(avg_loss)\n",
    "                print('Epoch: {}, Batch: {}, Avg. Loss: {}'.format(epoch + 1, batch_i, avg_loss))\n",
    "                running_loss = 0.0\n",
    "            \n",
    "                \n",
    "#         loss_over_time.append(epoch_loss)      \n",
    "#         print(\"Epoch: {}, Loss: {}\".format(epoch+1, epoch_loss))\n",
    "                \n",
    "    print(\"Finished training\")\n",
    "    return loss_over_time\n",
    "                \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 20000, Avg. Loss: 2.24786385178566\n",
      "Epoch: 1, Batch: 40000, Avg. Loss: 1.993544463992119\n",
      "Epoch: 1, Batch: 60000, Avg. Loss: 1.589820218503475\n",
      "Epoch: 2, Batch: 20000, Avg. Loss: 1.4087335712313651\n",
      "Epoch: 2, Batch: 40000, Avg. Loss: 1.2983681752085685\n",
      "Epoch: 2, Batch: 60000, Avg. Loss: 1.2443346768021584\n",
      "Epoch: 3, Batch: 20000, Avg. Loss: 1.201779434144497\n",
      "Epoch: 3, Batch: 40000, Avg. Loss: 1.1901785299181937\n",
      "Epoch: 3, Batch: 60000, Avg. Loss: 1.1735770249962807\n",
      "Epoch: 4, Batch: 20000, Avg. Loss: 1.156689530134201\n",
      "Epoch: 4, Batch: 40000, Avg. Loss: 1.1267522166967392\n",
      "Epoch: 4, Batch: 60000, Avg. Loss: 1.1235617685317993\n",
      "Epoch: 5, Batch: 20000, Avg. Loss: 1.1128305925130844\n",
      "Epoch: 5, Batch: 40000, Avg. Loss: 1.084244221240282\n",
      "Epoch: 5, Batch: 60000, Avg. Loss: 1.0962794167101384\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "\n",
    "\n",
    "training_loss = train(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "999%1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs):\n",
    "    \n",
    "    loss_over_time = [] # to track the loss as the network trains\n",
    "    \n",
    "    # move model to GPU\n",
    "    #model.to(\"cuda\")\n",
    "    \n",
    "    for epoch in range(n_epochs):  # loop over the dataset multiple times\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for batch_i, data in enumerate(trainloader):\n",
    "            # get the input images and their corresponding labels\n",
    "            inputs, labels = data\n",
    "            \n",
    "            # move images and label tensors to GPU\n",
    "            #inputs = inputs.to(\"cuda\")\n",
    "            #labels = labels.to(\"cuda\")\n",
    "\n",
    "            # zero the parameter (weight) gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass to get outputs\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # calculate the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # backward pass to calculate the parameter gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # update the parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # print loss statistics\n",
    "            # to convert loss into a scalar and add it to running_loss, we use .item()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if batch_i % 1000 == 999:    # print every 1000 batches\n",
    "                avg_loss = running_loss/1000\n",
    "                # record and print the avg loss over the 1000 batches\n",
    "                loss_over_time.append(avg_loss)\n",
    "                print('Epoch: {}, Batch: {}, Avg. Loss: {}'.format(epoch + 1, batch_i+1, avg_loss))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    return loss_over_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 1000, Avg. Loss: 2.291698361158371\n",
      "Epoch: 1, Batch: 2000, Avg. Loss: 2.255459939479828\n",
      "Epoch: 1, Batch: 3000, Avg. Loss: 2.118408938884735\n",
      "Epoch: 2, Batch: 1000, Avg. Loss: 1.7161077836751937\n",
      "Epoch: 2, Batch: 2000, Avg. Loss: 1.4990334876775742\n",
      "Epoch: 2, Batch: 3000, Avg. Loss: 1.3907651245594024\n",
      "Epoch: 3, Batch: 1000, Avg. Loss: 1.2120998161435128\n",
      "Epoch: 3, Batch: 2000, Avg. Loss: 1.1009270148277284\n",
      "Epoch: 3, Batch: 3000, Avg. Loss: 1.03816006731987\n",
      "Epoch: 4, Batch: 1000, Avg. Loss: 0.9974813283085823\n",
      "Epoch: 4, Batch: 2000, Avg. Loss: 0.9945689930021763\n",
      "Epoch: 4, Batch: 3000, Avg. Loss: 0.9704925980567932\n",
      "Epoch: 5, Batch: 1000, Avg. Loss: 0.951262921333313\n",
      "Epoch: 5, Batch: 2000, Avg. Loss: 0.9260910192728042\n",
      "Epoch: 5, Batch: 3000, Avg. Loss: 0.9278217017352581\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 5\n",
    "\n",
    "\n",
    "training_loss = train(n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GeForce RTX 2070 with Max-Q Design'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a function for the validation pass\n",
    "def validation(model, testloader, criterion):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    for images, labels in testloader:\n",
    "\n",
    "        images.resize_(images.shape[0], 784)\n",
    "\n",
    "        output = model.forward(images)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "        \n",
    "        # because output is log(softmax), so taking exp returns softmax\n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3..  Training Loss: 0.557..  Test Loss: 0.585..  Test Accuracy: 0.797\n",
      "Epoch: 1/3..  Training Loss: 0.578..  Test Loss: 0.598..  Test Accuracy: 0.791\n",
      "Epoch: 1/3..  Training Loss: 0.591..  Test Loss: 0.578..  Test Accuracy: 0.796\n",
      "Epoch: 1/3..  Training Loss: 0.552..  Test Loss: 0.598..  Test Accuracy: 0.790\n",
      "Epoch: 1/3..  Training Loss: 0.548..  Test Loss: 0.605..  Test Accuracy: 0.787\n",
      "Epoch: 1/3..  Training Loss: 0.544..  Test Loss: 0.571..  Test Accuracy: 0.802\n",
      "Epoch: 1/3..  Training Loss: 0.541..  Test Loss: 0.573..  Test Accuracy: 0.800\n",
      "Epoch: 1/3..  Training Loss: 0.549..  Test Loss: 0.566..  Test Accuracy: 0.804\n",
      "Epoch: 1/3..  Training Loss: 0.554..  Test Loss: 0.569..  Test Accuracy: 0.805\n",
      "Epoch: 1/3..  Training Loss: 0.544..  Test Loss: 0.578..  Test Accuracy: 0.796\n",
      "Epoch: 1/3..  Training Loss: 0.558..  Test Loss: 0.565..  Test Accuracy: 0.803\n",
      "Epoch: 1/3..  Training Loss: 0.539..  Test Loss: 0.560..  Test Accuracy: 0.807\n",
      "Epoch: 1/3..  Training Loss: 0.531..  Test Loss: 0.560..  Test Accuracy: 0.805\n",
      "Epoch: 1/3..  Training Loss: 0.524..  Test Loss: 0.568..  Test Accuracy: 0.803\n",
      "Epoch: 1/3..  Training Loss: 0.538..  Test Loss: 0.569..  Test Accuracy: 0.798\n",
      "Epoch: 1/3..  Training Loss: 0.536..  Test Loss: 0.552..  Test Accuracy: 0.808\n",
      "Epoch: 1/3..  Training Loss: 0.533..  Test Loss: 0.561..  Test Accuracy: 0.802\n",
      "Epoch: 1/3..  Training Loss: 0.529..  Test Loss: 0.557..  Test Accuracy: 0.805\n",
      "Epoch: 1/3..  Training Loss: 0.533..  Test Loss: 0.555..  Test Accuracy: 0.807\n",
      "Epoch: 1/3..  Training Loss: 0.527..  Test Loss: 0.549..  Test Accuracy: 0.812\n",
      "Epoch: 1/3..  Training Loss: 0.546..  Test Loss: 0.558..  Test Accuracy: 0.803\n",
      "Epoch: 1/3..  Training Loss: 0.499..  Test Loss: 0.547..  Test Accuracy: 0.808\n",
      "Epoch: 1/3..  Training Loss: 0.517..  Test Loss: 0.540..  Test Accuracy: 0.814\n",
      "Epoch: 2/3..  Training Loss: 0.524..  Test Loss: 0.541..  Test Accuracy: 0.809\n",
      "Epoch: 2/3..  Training Loss: 0.512..  Test Loss: 0.555..  Test Accuracy: 0.802\n",
      "Epoch: 2/3..  Training Loss: 0.518..  Test Loss: 0.544..  Test Accuracy: 0.810\n",
      "Epoch: 2/3..  Training Loss: 0.515..  Test Loss: 0.540..  Test Accuracy: 0.813\n",
      "Epoch: 2/3..  Training Loss: 0.529..  Test Loss: 0.552..  Test Accuracy: 0.804\n",
      "Epoch: 2/3..  Training Loss: 0.495..  Test Loss: 0.561..  Test Accuracy: 0.802\n",
      "Epoch: 2/3..  Training Loss: 0.532..  Test Loss: 0.539..  Test Accuracy: 0.813\n",
      "Epoch: 2/3..  Training Loss: 0.492..  Test Loss: 0.555..  Test Accuracy: 0.800\n",
      "Epoch: 2/3..  Training Loss: 0.529..  Test Loss: 0.531..  Test Accuracy: 0.813\n",
      "Epoch: 2/3..  Training Loss: 0.528..  Test Loss: 0.532..  Test Accuracy: 0.815\n",
      "Epoch: 2/3..  Training Loss: 0.510..  Test Loss: 0.524..  Test Accuracy: 0.817\n",
      "Epoch: 2/3..  Training Loss: 0.500..  Test Loss: 0.544..  Test Accuracy: 0.808\n",
      "Epoch: 2/3..  Training Loss: 0.472..  Test Loss: 0.529..  Test Accuracy: 0.816\n",
      "Epoch: 2/3..  Training Loss: 0.489..  Test Loss: 0.527..  Test Accuracy: 0.815\n",
      "Epoch: 2/3..  Training Loss: 0.517..  Test Loss: 0.526..  Test Accuracy: 0.816\n",
      "Epoch: 2/3..  Training Loss: 0.547..  Test Loss: 0.523..  Test Accuracy: 0.819\n",
      "Epoch: 2/3..  Training Loss: 0.501..  Test Loss: 0.518..  Test Accuracy: 0.819\n",
      "Epoch: 2/3..  Training Loss: 0.468..  Test Loss: 0.530..  Test Accuracy: 0.817\n",
      "Epoch: 2/3..  Training Loss: 0.488..  Test Loss: 0.533..  Test Accuracy: 0.814\n",
      "Epoch: 2/3..  Training Loss: 0.514..  Test Loss: 0.531..  Test Accuracy: 0.811\n",
      "Epoch: 2/3..  Training Loss: 0.517..  Test Loss: 0.524..  Test Accuracy: 0.815\n",
      "Epoch: 2/3..  Training Loss: 0.509..  Test Loss: 0.522..  Test Accuracy: 0.813\n",
      "Epoch: 2/3..  Training Loss: 0.508..  Test Loss: 0.537..  Test Accuracy: 0.813\n",
      "Epoch: 3/3..  Training Loss: 0.467..  Test Loss: 0.514..  Test Accuracy: 0.821\n",
      "Epoch: 3/3..  Training Loss: 0.463..  Test Loss: 0.536..  Test Accuracy: 0.810\n",
      "Epoch: 3/3..  Training Loss: 0.515..  Test Loss: 0.518..  Test Accuracy: 0.816\n",
      "Epoch: 3/3..  Training Loss: 0.515..  Test Loss: 0.528..  Test Accuracy: 0.813\n",
      "Epoch: 3/3..  Training Loss: 0.485..  Test Loss: 0.513..  Test Accuracy: 0.823\n",
      "Epoch: 3/3..  Training Loss: 0.465..  Test Loss: 0.519..  Test Accuracy: 0.819\n",
      "Epoch: 3/3..  Training Loss: 0.524..  Test Loss: 0.520..  Test Accuracy: 0.816\n",
      "Epoch: 3/3..  Training Loss: 0.513..  Test Loss: 0.520..  Test Accuracy: 0.815\n",
      "Epoch: 3/3..  Training Loss: 0.466..  Test Loss: 0.523..  Test Accuracy: 0.814\n",
      "Epoch: 3/3..  Training Loss: 0.482..  Test Loss: 0.504..  Test Accuracy: 0.825\n",
      "Epoch: 3/3..  Training Loss: 0.486..  Test Loss: 0.507..  Test Accuracy: 0.823\n",
      "Epoch: 3/3..  Training Loss: 0.470..  Test Loss: 0.519..  Test Accuracy: 0.818\n",
      "Epoch: 3/3..  Training Loss: 0.477..  Test Loss: 0.507..  Test Accuracy: 0.825\n",
      "Epoch: 3/3..  Training Loss: 0.499..  Test Loss: 0.515..  Test Accuracy: 0.818\n",
      "Epoch: 3/3..  Training Loss: 0.488..  Test Loss: 0.510..  Test Accuracy: 0.820\n",
      "Epoch: 3/3..  Training Loss: 0.451..  Test Loss: 0.506..  Test Accuracy: 0.824\n",
      "Epoch: 3/3..  Training Loss: 0.480..  Test Loss: 0.528..  Test Accuracy: 0.811\n",
      "Epoch: 3/3..  Training Loss: 0.469..  Test Loss: 0.507..  Test Accuracy: 0.821\n",
      "Epoch: 3/3..  Training Loss: 0.468..  Test Loss: 0.507..  Test Accuracy: 0.819\n",
      "Epoch: 3/3..  Training Loss: 0.462..  Test Loss: 0.505..  Test Accuracy: 0.821\n",
      "Epoch: 3/3..  Training Loss: 0.463..  Test Loss: 0.507..  Test Accuracy: 0.824\n",
      "Epoch: 3/3..  Training Loss: 0.478..  Test Loss: 0.496..  Test Accuracy: 0.826\n",
      "Epoch: 3/3..  Training Loss: 0.485..  Test Loss: 0.505..  Test Accuracy: 0.822\n",
      "Epoch: 3/3..  Training Loss: 0.495..  Test Loss: 0.508..  Test Accuracy: 0.818\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 40\n",
    "\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    for images, labels in iter(trainloader):\n",
    "        \n",
    "        steps += 1\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            # Make sure network is in eval mode for inference\n",
    "            # no dropouts\n",
    "            model.eval()\n",
    "            \n",
    "            # Turn off gradients for validation, saves memory and computations\n",
    "            with torch.no_grad():\n",
    "                test_loss, accuracy = validation(model, testloader, criterion)\n",
    "                \n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "            \n",
    "            running_loss = 0\n",
    "            \n",
    "            # Make sure training is back on\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.4575e+00, 1.3439e+01, 2.0471e+00, 4.4669e+02, 1.5529e+00, 1.5067e-02,\n",
       "         8.1384e-01, 4.0921e-02, 2.4455e-01, 9.1974e-02]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to avoid having dropout when doing validation\n",
    "model.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.view(1, 784)\n",
    "\n",
    "# Calculate the class probabilities (softmax) for img\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img)\n",
    "\n",
    "ps = torch.exp(output)\n",
    "\n",
    "# Plot the image and probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
