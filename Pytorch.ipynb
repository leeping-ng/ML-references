{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "data_transform = transforms.ToTensor()\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=True, transform=data_transform)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.FashionMNIST('F_MNIST_data/', download=True, train=False, transform=data_transform)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data, number of images:  60000\n",
      "Test data, number of images:  10000\n"
     ]
    }
   ],
   "source": [
    "print('Train data, number of images: ', len(trainset))\n",
    "print('Test data, number of images: ', len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement a function for the validation pass\n",
    "def validation(model, testloader, criterion):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    for images, labels in testloader:\n",
    "\n",
    "        images.resize_(images.shape[0], 784)\n",
    "\n",
    "        output = model.forward(images)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "\n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/3..  Training Loss: 0.557..  Test Loss: 0.585..  Test Accuracy: 0.797\n",
      "Epoch: 1/3..  Training Loss: 0.578..  Test Loss: 0.598..  Test Accuracy: 0.791\n",
      "Epoch: 1/3..  Training Loss: 0.591..  Test Loss: 0.578..  Test Accuracy: 0.796\n",
      "Epoch: 1/3..  Training Loss: 0.552..  Test Loss: 0.598..  Test Accuracy: 0.790\n",
      "Epoch: 1/3..  Training Loss: 0.548..  Test Loss: 0.605..  Test Accuracy: 0.787\n",
      "Epoch: 1/3..  Training Loss: 0.544..  Test Loss: 0.571..  Test Accuracy: 0.802\n",
      "Epoch: 1/3..  Training Loss: 0.541..  Test Loss: 0.573..  Test Accuracy: 0.800\n",
      "Epoch: 1/3..  Training Loss: 0.549..  Test Loss: 0.566..  Test Accuracy: 0.804\n",
      "Epoch: 1/3..  Training Loss: 0.554..  Test Loss: 0.569..  Test Accuracy: 0.805\n",
      "Epoch: 1/3..  Training Loss: 0.544..  Test Loss: 0.578..  Test Accuracy: 0.796\n",
      "Epoch: 1/3..  Training Loss: 0.558..  Test Loss: 0.565..  Test Accuracy: 0.803\n",
      "Epoch: 1/3..  Training Loss: 0.539..  Test Loss: 0.560..  Test Accuracy: 0.807\n",
      "Epoch: 1/3..  Training Loss: 0.531..  Test Loss: 0.560..  Test Accuracy: 0.805\n",
      "Epoch: 1/3..  Training Loss: 0.524..  Test Loss: 0.568..  Test Accuracy: 0.803\n",
      "Epoch: 1/3..  Training Loss: 0.538..  Test Loss: 0.569..  Test Accuracy: 0.798\n",
      "Epoch: 1/3..  Training Loss: 0.536..  Test Loss: 0.552..  Test Accuracy: 0.808\n",
      "Epoch: 1/3..  Training Loss: 0.533..  Test Loss: 0.561..  Test Accuracy: 0.802\n",
      "Epoch: 1/3..  Training Loss: 0.529..  Test Loss: 0.557..  Test Accuracy: 0.805\n",
      "Epoch: 1/3..  Training Loss: 0.533..  Test Loss: 0.555..  Test Accuracy: 0.807\n",
      "Epoch: 1/3..  Training Loss: 0.527..  Test Loss: 0.549..  Test Accuracy: 0.812\n",
      "Epoch: 1/3..  Training Loss: 0.546..  Test Loss: 0.558..  Test Accuracy: 0.803\n",
      "Epoch: 1/3..  Training Loss: 0.499..  Test Loss: 0.547..  Test Accuracy: 0.808\n",
      "Epoch: 1/3..  Training Loss: 0.517..  Test Loss: 0.540..  Test Accuracy: 0.814\n",
      "Epoch: 2/3..  Training Loss: 0.524..  Test Loss: 0.541..  Test Accuracy: 0.809\n",
      "Epoch: 2/3..  Training Loss: 0.512..  Test Loss: 0.555..  Test Accuracy: 0.802\n",
      "Epoch: 2/3..  Training Loss: 0.518..  Test Loss: 0.544..  Test Accuracy: 0.810\n",
      "Epoch: 2/3..  Training Loss: 0.515..  Test Loss: 0.540..  Test Accuracy: 0.813\n",
      "Epoch: 2/3..  Training Loss: 0.529..  Test Loss: 0.552..  Test Accuracy: 0.804\n",
      "Epoch: 2/3..  Training Loss: 0.495..  Test Loss: 0.561..  Test Accuracy: 0.802\n",
      "Epoch: 2/3..  Training Loss: 0.532..  Test Loss: 0.539..  Test Accuracy: 0.813\n",
      "Epoch: 2/3..  Training Loss: 0.492..  Test Loss: 0.555..  Test Accuracy: 0.800\n",
      "Epoch: 2/3..  Training Loss: 0.529..  Test Loss: 0.531..  Test Accuracy: 0.813\n",
      "Epoch: 2/3..  Training Loss: 0.528..  Test Loss: 0.532..  Test Accuracy: 0.815\n",
      "Epoch: 2/3..  Training Loss: 0.510..  Test Loss: 0.524..  Test Accuracy: 0.817\n",
      "Epoch: 2/3..  Training Loss: 0.500..  Test Loss: 0.544..  Test Accuracy: 0.808\n",
      "Epoch: 2/3..  Training Loss: 0.472..  Test Loss: 0.529..  Test Accuracy: 0.816\n",
      "Epoch: 2/3..  Training Loss: 0.489..  Test Loss: 0.527..  Test Accuracy: 0.815\n",
      "Epoch: 2/3..  Training Loss: 0.517..  Test Loss: 0.526..  Test Accuracy: 0.816\n",
      "Epoch: 2/3..  Training Loss: 0.547..  Test Loss: 0.523..  Test Accuracy: 0.819\n",
      "Epoch: 2/3..  Training Loss: 0.501..  Test Loss: 0.518..  Test Accuracy: 0.819\n",
      "Epoch: 2/3..  Training Loss: 0.468..  Test Loss: 0.530..  Test Accuracy: 0.817\n",
      "Epoch: 2/3..  Training Loss: 0.488..  Test Loss: 0.533..  Test Accuracy: 0.814\n",
      "Epoch: 2/3..  Training Loss: 0.514..  Test Loss: 0.531..  Test Accuracy: 0.811\n",
      "Epoch: 2/3..  Training Loss: 0.517..  Test Loss: 0.524..  Test Accuracy: 0.815\n",
      "Epoch: 2/3..  Training Loss: 0.509..  Test Loss: 0.522..  Test Accuracy: 0.813\n",
      "Epoch: 2/3..  Training Loss: 0.508..  Test Loss: 0.537..  Test Accuracy: 0.813\n",
      "Epoch: 3/3..  Training Loss: 0.467..  Test Loss: 0.514..  Test Accuracy: 0.821\n",
      "Epoch: 3/3..  Training Loss: 0.463..  Test Loss: 0.536..  Test Accuracy: 0.810\n",
      "Epoch: 3/3..  Training Loss: 0.515..  Test Loss: 0.518..  Test Accuracy: 0.816\n",
      "Epoch: 3/3..  Training Loss: 0.515..  Test Loss: 0.528..  Test Accuracy: 0.813\n",
      "Epoch: 3/3..  Training Loss: 0.485..  Test Loss: 0.513..  Test Accuracy: 0.823\n",
      "Epoch: 3/3..  Training Loss: 0.465..  Test Loss: 0.519..  Test Accuracy: 0.819\n",
      "Epoch: 3/3..  Training Loss: 0.524..  Test Loss: 0.520..  Test Accuracy: 0.816\n",
      "Epoch: 3/3..  Training Loss: 0.513..  Test Loss: 0.520..  Test Accuracy: 0.815\n",
      "Epoch: 3/3..  Training Loss: 0.466..  Test Loss: 0.523..  Test Accuracy: 0.814\n",
      "Epoch: 3/3..  Training Loss: 0.482..  Test Loss: 0.504..  Test Accuracy: 0.825\n",
      "Epoch: 3/3..  Training Loss: 0.486..  Test Loss: 0.507..  Test Accuracy: 0.823\n",
      "Epoch: 3/3..  Training Loss: 0.470..  Test Loss: 0.519..  Test Accuracy: 0.818\n",
      "Epoch: 3/3..  Training Loss: 0.477..  Test Loss: 0.507..  Test Accuracy: 0.825\n",
      "Epoch: 3/3..  Training Loss: 0.499..  Test Loss: 0.515..  Test Accuracy: 0.818\n",
      "Epoch: 3/3..  Training Loss: 0.488..  Test Loss: 0.510..  Test Accuracy: 0.820\n",
      "Epoch: 3/3..  Training Loss: 0.451..  Test Loss: 0.506..  Test Accuracy: 0.824\n",
      "Epoch: 3/3..  Training Loss: 0.480..  Test Loss: 0.528..  Test Accuracy: 0.811\n",
      "Epoch: 3/3..  Training Loss: 0.469..  Test Loss: 0.507..  Test Accuracy: 0.821\n",
      "Epoch: 3/3..  Training Loss: 0.468..  Test Loss: 0.507..  Test Accuracy: 0.819\n",
      "Epoch: 3/3..  Training Loss: 0.462..  Test Loss: 0.505..  Test Accuracy: 0.821\n",
      "Epoch: 3/3..  Training Loss: 0.463..  Test Loss: 0.507..  Test Accuracy: 0.824\n",
      "Epoch: 3/3..  Training Loss: 0.478..  Test Loss: 0.496..  Test Accuracy: 0.826\n",
      "Epoch: 3/3..  Training Loss: 0.485..  Test Loss: 0.505..  Test Accuracy: 0.822\n",
      "Epoch: 3/3..  Training Loss: 0.495..  Test Loss: 0.508..  Test Accuracy: 0.818\n"
     ]
    }
   ],
   "source": [
    "epochs = 3\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 40\n",
    "\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    for images, labels in iter(trainloader):\n",
    "        \n",
    "        steps += 1\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            # Make sure network is in eval mode for inference\n",
    "            model.eval()\n",
    "            \n",
    "            # Turn off gradients for validation, saves memory and computations\n",
    "            with torch.no_grad():\n",
    "                test_loss, accuracy = validation(model, testloader, criterion)\n",
    "                \n",
    "            print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "                  \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                  \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "                  \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "            \n",
    "            running_loss = 0\n",
    "            \n",
    "            # Make sure training is back on\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7.4575e+00, 1.3439e+01, 2.0471e+00, 4.4669e+02, 1.5529e+00, 1.5067e-02,\n",
       "         8.1384e-01, 4.0921e-02, 2.4455e-01, 9.1974e-02]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[0]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.view(1, 784)\n",
    "\n",
    "# Calculate the class probabilities (softmax) for img\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img)\n",
    "\n",
    "ps = torch.exp(output)\n",
    "\n",
    "# Plot the image and probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
